<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Subpixel land cover classification for improved urban area estimates using Landsat | Geocomputation with R</title>
  <meta name="description" content="5 Subpixel land cover classification for improved urban area estimates using Landsat | Geocomputation with R is for people who want to analyze, visualize and model geographic data with open source software. It is based on R, a statistical programming language that has powerful data processing, visualization, and geospatial capabilities. The book equips you with the knowledge and skills to tackle a wide range of issues manifested in geographic data, including those with scientific, societal, and environmental implications. This book will interest people from many backgrounds, especially Geographic Information Systems (GIS) users interested in applying their domain-specific knowledge in a powerful open source language for data science, and R users interested in extending their skills to handle spatial data." />
  <meta name="generator" content="bookdown 0.17.2 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Subpixel land cover classification for improved urban area estimates using Landsat | Geocomputation with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://geocompr.robinlovelace.net/" />
  <meta property="og:image" content="https://geocompr.robinlovelace.net/images/cover.png" />
  <meta property="og:description" content="5 Subpixel land cover classification for improved urban area estimates using Landsat | Geocomputation with R is for people who want to analyze, visualize and model geographic data with open source software. It is based on R, a statistical programming language that has powerful data processing, visualization, and geospatial capabilities. The book equips you with the knowledge and skills to tackle a wide range of issues manifested in geographic data, including those with scientific, societal, and environmental implications. This book will interest people from many backgrounds, especially Geographic Information Systems (GIS) users interested in applying their domain-specific knowledge in a powerful open source language for data science, and R users interested in extending their skills to handle spatial data." />
  <meta name="github-repo" content="Robinlovelace/geocompr" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Subpixel land cover classification for improved urban area estimates using Landsat | Geocomputation with R" />
  
  <meta name="twitter:description" content="5 Subpixel land cover classification for improved urban area estimates using Landsat | Geocomputation with R is for people who want to analyze, visualize and model geographic data with open source software. It is based on R, a statistical programming language that has powerful data processing, visualization, and geospatial capabilities. The book equips you with the knowledge and skills to tackle a wide range of issues manifested in geographic data, including those with scientific, societal, and environmental implications. This book will interest people from many backgrounds, especially Geographic Information Systems (GIS) users interested in applying their domain-specific knowledge in a powerful open source language for data science, and R users interested in extending their skills to handle spatial data." />
  <meta name="twitter:image" content="https://geocompr.robinlovelace.net/images/cover.png" />

<meta name="author" content="Robin Lovelace, Jakub Nowosad, Jannes Muenchow" />


<meta name="date" content="2020-02-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A MacLachlan PhD</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-contribute"><i class="fa fa-check"></i>How to contribute?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reproducibility"><i class="fa fa-check"></i>Reproducibility</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#supporting-the-project"><i class="fa fa-check"></i>Supporting the project</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-this-book-is-for"><i class="fa fa-check"></i>Who this book is for</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#how-to-read-this-book"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#why-r"><i class="fa fa-check"></i>Why R?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#real-world-impact"><i class="fa fa-check"></i>Real-world impact</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="acknowledgements-1.html"><a href="acknowledgements-1.html"><i class="fa fa-check"></i>Acknowledgements</a><ul>
<li class="chapter" data-level="" data-path="acknowledgements-1.html"><a href="acknowledgements-1.html#personal"><i class="fa fa-check"></i>Personal</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-1.html"><a href="acknowledgements-1.html#funding-and-data-access"><i class="fa fa-check"></i>Funding and data access</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="declaration-of-authorship.html"><a href="declaration-of-authorship.html"><i class="fa fa-check"></i>Declaration of Authorship</a><ul>
<li class="chapter" data-level="" data-path="declaration-of-authorship.html"><a href="declaration-of-authorship.html#author-attribution-statements"><i class="fa fa-check"></i>Author attribution statements</a><ul>
<li class="chapter" data-level="" data-path="declaration-of-authorship.html"><a href="declaration-of-authorship.html#chapter-4-paper-1a"><i class="fa fa-check"></i>Chapter 4, paper 1a</a></li>
<li class="chapter" data-level="" data-path="declaration-of-authorship.html"><a href="declaration-of-authorship.html#chapter-4-paper-1b"><i class="fa fa-check"></i>Chapter 4, paper 1b</a></li>
<li class="chapter" data-level="" data-path="declaration-of-authorship.html"><a href="declaration-of-authorship.html#chapter-5-paper-2"><i class="fa fa-check"></i>Chapter 5, paper 2</a></li>
<li class="chapter" data-level="" data-path="declaration-of-authorship.html"><a href="declaration-of-authorship.html#chapter-6-paper-3"><i class="fa fa-check"></i>Chapter 6, paper 3</a></li>
<li class="chapter" data-level="" data-path="declaration-of-authorship.html"><a href="declaration-of-authorship.html#chapter-7-paper-4"><i class="fa fa-check"></i>Chapter 7, paper 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#an-expanding-urban-area"><i class="fa fa-check"></i><b>1.1</b> An expanding urban area</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#defining-urban-area"><i class="fa fa-check"></i><b>1.2</b> Defining urban area</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#types-of-urban-expansion"><i class="fa fa-check"></i><b>1.3</b> Types of urban expansion</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#urban-growth"><i class="fa fa-check"></i><b>1.3.1</b> Urban growth</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#urban-sprawl"><i class="fa fa-check"></i><b>1.3.2</b> Urban sprawl</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#urban-growth-and-sprawl-in-earth-observation"><i class="fa fa-check"></i><b>1.3.3</b> Urban growth and sprawl in Earth observation</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#the-urban-heat-island-effect"><i class="fa fa-check"></i><b>1.4</b> The urban heat island effect</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.4.1</b> Introduction</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#urban-heat-island-theory"><i class="fa fa-check"></i><b>1.4.2</b> Urban heat island theory</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction.html"><a href="introduction.html#urban-heat-island-categories"><i class="fa fa-check"></i><b>1.4.3</b> Urban heat island categories</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction.html"><a href="introduction.html#heat-island-layers"><i class="fa fa-check"></i><b>1.4.4</b> Heat island layers</a></li>
<li class="chapter" data-level="1.4.5" data-path="introduction.html"><a href="introduction.html#heat-island-temporal-form"><i class="fa fa-check"></i><b>1.4.5</b> Heat island temporal form</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#urban-heat-island-impacts"><i class="fa fa-check"></i><b>1.5</b> Urban heat island impacts</a><ul>
<li class="chapter" data-level="1.5.1" data-path="introduction.html"><a href="introduction.html#social-impacts"><i class="fa fa-check"></i><b>1.5.1</b> Social impacts</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction.html"><a href="introduction.html#environmental-impacts"><i class="fa fa-check"></i><b>1.5.2</b> Environmental impacts</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction.html"><a href="introduction.html#economic-impacts"><i class="fa fa-check"></i><b>1.5.3</b> Economic impacts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><i class="fa fa-check"></i><b>2</b> Monitoring urban growth and the urban heat island effect using Earth observation</a><ul>
<li class="chapter" data-level="2.1" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#introduction-2"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#monitoring-land-cover-change"><i class="fa fa-check"></i><b>2.2</b> Monitoring land cover change</a><ul>
<li class="chapter" data-level="2.2.1" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#image-preprocessing"><i class="fa fa-check"></i><b>2.2.1</b> Image preprocessing</a></li>
<li class="chapter" data-level="2.2.2" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#image-classification"><i class="fa fa-check"></i><b>2.2.2</b> Image classification</a></li>
<li class="chapter" data-level="2.2.3" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#recent-classification-methodologies"><i class="fa fa-check"></i><b>2.2.3</b> Recent classification methodologies</a></li>
<li class="chapter" data-level="2.2.4" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#comparison-of-recent-classification-methodologies"><i class="fa fa-check"></i><b>2.2.4</b> Comparison of recent classification methodologies</a></li>
<li class="chapter" data-level="2.2.5" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#image-spectral-combinations"><i class="fa fa-check"></i><b>2.2.5</b> Image spectral combinations</a></li>
<li class="chapter" data-level="2.2.6" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#data-fusion-methodologies"><i class="fa fa-check"></i><b>2.2.6</b> Data fusion methodologies</a></li>
<li class="chapter" data-level="2.2.7" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#output-evaluation"><i class="fa fa-check"></i><b>2.2.7</b> Output evaluation</a></li>
<li class="chapter" data-level="2.2.8" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#classification-methodological-conclusion"><i class="fa fa-check"></i><b>2.2.8</b> Classification methodological conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#monitoring-urban-heat-islands"><i class="fa fa-check"></i><b>2.3</b> Monitoring urban heat islands</a><ul>
<li class="chapter" data-level="2.3.1" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#traditional-urban-heat-island-methodologies"><i class="fa fa-check"></i><b>2.3.1</b> Traditional urban heat island methodologies</a></li>
<li class="chapter" data-level="2.3.2" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#remotely-sensed-land-surface-temperature"><i class="fa fa-check"></i><b>2.3.2</b> Remotely sensed land surface temperature</a></li>
<li class="chapter" data-level="2.3.3" data-path="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html"><a href="monitoring-urban-growth-and-the-urban-heat-island-effect-using-earth-observation.html#localised-temperature-mitigation"><i class="fa fa-check"></i><b>2.3.3</b> Localised temperature mitigation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="research-aim-and-objectives.html"><a href="research-aim-and-objectives.html"><i class="fa fa-check"></i><b>3</b> Research aim and objectives</a><ul>
<li class="chapter" data-level="3.1" data-path="research-aim-and-objectives.html"><a href="research-aim-and-objectives.html#study-site"><i class="fa fa-check"></i><b>3.1</b> Study site</a></li>
<li class="chapter" data-level="3.2" data-path="research-aim-and-objectives.html"><a href="research-aim-and-objectives.html#thesis-structure-and-methodological-outline"><i class="fa fa-check"></i><b>3.2</b> Thesis structure and methodological outline</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><i class="fa fa-check"></i><b>4</b> Urban growth dynamics in Perth, Western Australia: using applied remote sensing for sustainable future planning</a><ul>
<li class="chapter" data-level="4.1" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#abstract"><i class="fa fa-check"></i><b>4.1</b> Abstract</a></li>
<li class="chapter" data-level="4.2" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#introduction-3"><i class="fa fa-check"></i><b>4.2</b> Introduction</a><ul>
<li class="chapter" data-level="4.2.1" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#earth-observation-for-monitoring-urban-change"><i class="fa fa-check"></i><b>4.2.1</b> Earth observation for monitoring urban change</a></li>
<li class="chapter" data-level="4.2.2" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#the-case-of-perth"><i class="fa fa-check"></i><b>4.2.2</b> The case of Perth</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#materials-and-methods"><i class="fa fa-check"></i><b>4.3</b> Materials and methods</a><ul>
<li class="chapter" data-level="4.3.1" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#data-preprocessing"><i class="fa fa-check"></i><b>4.3.1</b> Data preprocessing</a></li>
<li class="chapter" data-level="4.3.2" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#data-classification"><i class="fa fa-check"></i><b>4.3.2</b> Data classification</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#results"><i class="fa fa-check"></i><b>4.4</b> Results</a></li>
<li class="chapter" data-level="4.5" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#discussion"><i class="fa fa-check"></i><b>4.5</b> Discussion</a></li>
<li class="chapter" data-level="4.6" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#recommendations"><i class="fa fa-check"></i><b>4.6</b> Recommendations</a></li>
<li class="chapter" data-level="4.7" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#supplementary-material"><i class="fa fa-check"></i><b>4.7</b> Supplementary material</a><ul>
<li class="chapter" data-level="4.7.1" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#standardisation-and-normalisation"><i class="fa fa-check"></i><b>4.7.1</b> Standardisation and normalisation</a></li>
<li class="chapter" data-level="4.7.2" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#accuracy-assessment"><i class="fa fa-check"></i><b>4.7.2</b> Accuracy assessment</a></li>
<li class="chapter" data-level="4.7.3" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#other-considered-data-and-approaches"><i class="fa fa-check"></i><b>4.7.3</b> Other considered data and approaches</a></li>
<li class="chapter" data-level="4.7.4" data-path="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html"><a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html#chapter-data-list"><i class="fa fa-check"></i><b>4.7.4</b> Chapter data list</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><i class="fa fa-check"></i><b>5</b> Subpixel land cover classification for improved urban area estimates using Landsat</a><ul>
<li class="chapter" data-level="5.1" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#abstract-1"><i class="fa fa-check"></i><b>5.1</b> Abstract</a></li>
<li class="chapter" data-level="5.2" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#introduction-4"><i class="fa fa-check"></i><b>5.2</b> Introduction</a></li>
<li class="chapter" data-level="5.3" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#study-area"><i class="fa fa-check"></i><b>5.3</b> Study area</a></li>
<li class="chapter" data-level="5.4" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#data"><i class="fa fa-check"></i><b>5.4</b> Data</a><ul>
<li class="chapter" data-level="5.4.1" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#landsat-data"><i class="fa fa-check"></i><b>5.4.1</b> Landsat data</a></li>
<li class="chapter" data-level="5.4.2" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#high-spatial-resolution-airborne-imagery"><i class="fa fa-check"></i><b>5.4.2</b> High spatial resolution airborne imagery</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#methodology"><i class="fa fa-check"></i><b>5.5</b> Methodology</a><ul>
<li class="chapter" data-level="5.5.1" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#landsat-preprocessing"><i class="fa fa-check"></i><b>5.5.1</b> Landsat preprocessing</a></li>
<li class="chapter" data-level="5.5.2" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#landsat-classification"><i class="fa fa-check"></i><b>5.5.2</b> Landsat classification</a></li>
<li class="chapter" data-level="5.5.3" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#google-earth-landsat-accuracy-assessment"><i class="fa fa-check"></i><b>5.5.3</b> Google Earth Landsat accuracy assessment</a></li>
<li class="chapter" data-level="5.5.4" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#aerial-image-classification"><i class="fa fa-check"></i><b>5.5.4</b> Aerial image classification</a></li>
<li class="chapter" data-level="5.5.5" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#dataset-comparison-and-landsat-refinement"><i class="fa fa-check"></i><b>5.5.5</b> Dataset comparison and Landsat refinement</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#results-1"><i class="fa fa-check"></i><b>5.6</b> Results</a><ul>
<li class="chapter" data-level="5.6.1" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#orthophoto-and-landsat-land-cover-comparison"><i class="fa fa-check"></i><b>5.6.1</b> Orthophoto and Landsat land cover comparison</a></li>
<li class="chapter" data-level="5.6.2" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#comparison-between-landsat-and-high-spatial-resolution-impervious-surface-estimates"><i class="fa fa-check"></i><b>5.6.2</b> Comparison between Landsat and high spatial resolution impervious surface estimates</a></li>
<li class="chapter" data-level="5.6.3" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#refining-landsat-estimations-using-high-spatial-resolution-data"><i class="fa fa-check"></i><b>5.6.3</b> Refining Landsat estimations using high spatial resolution data</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#discussion-1"><i class="fa fa-check"></i><b>5.7</b> Discussion</a></li>
<li class="chapter" data-level="5.8" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#conclusion"><i class="fa fa-check"></i><b>5.8</b> Conclusion</a></li>
<li class="chapter" data-level="5.9" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#supplementary-material-1"><i class="fa fa-check"></i><b>5.9</b> Supplementary material</a><ul>
<li class="chapter" data-level="5.9.1" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#classification-methodologies"><i class="fa fa-check"></i><b>5.9.1</b> Classification methodologies</a></li>
<li class="chapter" data-level="5.9.2" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#other-considered-data-and-approaches-1"><i class="fa fa-check"></i><b>5.9.2</b> Other considered data and approaches</a></li>
<li class="chapter" data-level="5.9.3" data-path="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html"><a href="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat.html#chapter-data-list-1"><i class="fa fa-check"></i><b>5.9.3</b> Chapter data list</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Geocomputation with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="subpixel-land-cover-classification-for-improved-urban-area-estimates-using-landsat" class="section level1">
<h1><span class="header-section-number">5</span> Subpixel land cover classification for improved urban area estimates using Landsat</h1>
<div id="abstract-1" class="section level2">
<h2><span class="header-section-number">5.1</span> Abstract</h2>
<p>Urban areas are Earth’s fastest growing land use that impact hydrological and ecological systems and the surface energy balance. The identification and extraction of accurate spatial information relating to urban areas is essential for future sustainable city planning owing to its importance within global environmental change and human-environment interactions. However, monitoring urban expansion using medium resolution (30-250 m) imagery remains challenging due to the variety of surface materials that contribute to measured reflectance resulting in spectrally mixed pixels. This research integrates high spatial resolution orthophotos and Landsat imagery to identify differences across a range of diverse urban subsets within the rapidly expanding Perth Metropolitan Region, Western Australia. Results indicate that calibrating Landsat derived sub-pixel land cover estimates with correction values (calculated from spatially explicit comparisons of sub-pixel Landsat values to classified high resolution data which accounts for over (under) estimations of Landsat) reduces moderate resolution urban area over (under) estimates by on average 55.08% for the Perth Metropolitan Region. This approach can be applied to other urban areas globally through use of frequently available and/or low cost high spatial resolution imagery (e.g. using Google Earth). This will improve urban growth estimations to help monitor and measure change whilst providing metrics to facilitate sustainable urban development targets within cities around the world.</p>
</div>
<div id="introduction-4" class="section level2">
<h2><span class="header-section-number">5.2</span> Introduction</h2>
<p>Urban areas are estimated to cover only 0.5% of Earth’s surface yet are one of the fastest growing land use per area basis (Bettencourt and West, 2010; Schneider et al., 2010, 2009). Population growth has resulted in increased urbanisation with 54% of the planet’s seven billion people in 2014 residing in urban areas with an additional 2.5 billion urban dwellers projected by 2050, whilst concurrently increasing the proportion of world’s urban population to 66% (Powell et al., 2007; Powell and Roberts, 2010; Sexton et al., 2013; Sharifi and Lehmann, 2014; Song et al., 2016; United Nations, Department of Economic and Social Affairs, 2014). Alteration of natural land cover to anthropogenic impervious surfaces has been identified as the most extreme cumulative effect of land cover change, generating numerous socio-economic consequences including: amenity provision efficiency, ecological degradation and the Urban Heat Island (UHI) effect (Cai et al., 2016; Howard, 1988; Hu and Brunsell, 2015; Xie and Zhou, 2015). Accurate information on urban land use and land cover is therefore imperative for monitoring expansion and planning policy targeting for future sustainable development of our cities (Bettencourt and West, 2010; Wu and Murray, 2003). Earth Observation (EO) enables consistent, detailed characterisation of the actual urban footprint of a city having been mapped and monitored using remotely sensed data at a range of spatial and temporal scales for associated implications (Akbari et al., 2003; Friedl et al., 2002; Imhoff et al., 1997; Schneider et al., 2010; Sexton et al., 2013). However, accurate and consistent monitoring of urban land cover is frequently precluded by coarse spatial (e.g. 1 km Moderate Resolution Imaging Spectroradiometer (MODIS) land cover product) and temporal (e.g. 2000 and 2010 GlobeLand30 product) resolution of such datasets (Lu et al., 2014; Song et al., 2016).</p>
<p>Urban mapping remains challenging due to the heterogeneity of surface materials and surface structure which contributes to pixel surface reflectance that are often difficult to disentangle (Herold et al., 2002; Lu et al., 2011; Schneider, 2012; Varshney and Rajesh, 2014). When delineating urban land cover from remotely sensed data, spatial resolution is considered the most important factor which provides increased visibility of discrete surface features (e.g. buildings) and greater pixel homogeneity over medium to coarse spatial resolution satellite imagery (e.g. Landsat and MODIS) (Myint et al., 2011). Nevertheless, high spatial resolution data often lack temporal acquisition consistency (e.g. airborne orthophotos) or are expensive to purchase (e.g. commercial satellite imagery). Consequently, in order to best monitor urban land use and land cover change, datasets must have an adequate spatial and temporal resolution to discern change. In this regard, data from the Landsat series of satellites provides the longest time-series of consistent, medium spatial resolution imagery that has been extensively applied to urban area mapping (Powell et al., 2007; Schneider and Mertes, 2014; Song et al., 2016; Sundarakumar et al., 2012; Wilson et al., 2003; Yuan et al., 2005). Accurate quantification of anthropogenic landscape modification is of critical importance due to associated environmental, anthropogenic and climatic impacts (Kalnay and Cai, 2003). Urban estimates from Landsat data have been used within global biogeochemistry and climate models (Zhu and Woodcock, 2014), further scientific studies such as UHI investigations (Hu et al., 2015) and targeted urban development policies (Hepinstall-Cymerman et al., 2013; Schneider et al., 2005). Whilst comparative studies (e.g. Li et al., 2014) have shown marginal holistic image accuracy difference between algorithm selection on per-pixel Landsat classification assuming sufficient training data. Traditional per-pixel methods, such as the maximum likelihood classifier (discussed in supplementary section 5.9.1), have been found to significantly over or underestimate urban area from Landsat data (Lu et al., 2011; Wu and Murray, 2003). Addressing this error is important when accurate classifications are required for monitoring change in land use patterns whereby calculations of urban extent can influence decision-making (e.g. policy for sustainable urban development) (Bagan and Yamagata, 2014; Hepinstall-Cymerman et al., 2013; Miller and Small, 2003; Schneider et al., 2005). Due to the heterogeneity of urban areas, sub-pixel classification methodologies have been increasingly applied to medium spatial resolution data to more accurately represent the mixture of land covers within a pixel (Lu et al., 2011; Lu and Weng, 2006; Powell and Roberts, 2008; Wang et al., 2013; Weng and Pu, 2013). This has been achieved through variations of Spectral Mixture Analysis (SMA) where a set number of representative endmembers, frequently following the Vegetation, Impervious and Soil (V-I-S) framework, are used to model the entire image based on their spectral characteristics (Powell et al., 2007; Ridd, 1995). However, endmembers may not fully represent image spectral variability or a pixel may be modelled by endmembers that do not represent materials within its field of view resulting in an inability to adequately portray the high spectral heterogeneity of the urban landscape (Powell et al., 2007). Support Vector Machine (SVM) spectral unmixing attempts to resolve this issue through consideration of a large number of training pixels which provides preferential accuracy in comparison to SMA although high dimensional data and large training samples can hinder its performance (Wang et al., 2013).</p>
<p>Comparatively the novel sub and hard pixel Import Vector Machine (IVM) classifier permits simultaneous multi-class comparison whilst continuously testing training samples for validity providing a more accurate solution (Roscher et al., 2012). IVM has been found to consistently outperform decision trees, artificial neural networks and maximum likelihood algorithms (Huang et al., 2002; Kotsiantis et al., 2006; Watanachaturaporn et al., 2008), with preferential (Braun et al., 2012) and comparable results to SVM (Roscher et al., 2010). However, due to the heterogeneity of urban areas it is important to calibrate these sub-pixel approaches against high spatial resolution data that capture the diverse characteristics found within urban environments (Lu et al., 2011). Perth, Western Australia (WA) is characterised by extensive urban diversity, surpassing all other major Australian and United States cities in terms of suburban development (Kelly et al., 2011; U.S. Department of Commerce, 2013). It therefore provides a suitable case study for assessing the ability of Landsat to map urban development, which is a pre-requisite for appropriate policy incorporation. This paper describes an approach to map the urban extent of the Perth Metropolitan Region (PMR) using an IVM classifier applied to medium spatial resolution imagery. The impact of sub-pixel land cover heterogeneity is investigated by comparing the urban area estimates to those derived from very high spatial resolution (20 cm) imagery. An innovative, spatially explicit correction to account for over (or under) estimation of urban area is derived which improves the urban land cover estimates from medium resolution imagery.</p>
</div>
<div id="study-area" class="section level2">
<h2><span class="header-section-number">5.3</span> Study area</h2>
<p>The PMR (Figure 5 1 (a)), WA has experienced sustained urban development since the 21st century in response to a rapidly growing resource sector (Kennewell and Shaw, 2008). The majority of recent urban growth within the PMR has transpired as outward low-density development resulting in a maximum population density of 3,662 km2 which is 33.45% and 24.83% lower than Melbourne (10,827) and Sydney (14,747) respectively (ABS, 2015; Western Australian Planning Commission, 2015a). The notion of the ‘Australian dream’, depicted as detached living in a green suburb, is most pronounced in Perth (Western Australian Planning Commission, 2013a). As a result 79% of the current housing is detached, compared to 62% in Sydney, 72% in Melbourne and a national average of 74% (Kelly et al., 2011; Western Australian Planning Commission, 2013b). Globally, Australia surpasses other developed countries in terms of detached suburban living with England having 42% of housing as either detached or semi-detached (Department for Communities and Local Government, 2015). Similarly only 64.2% of United States of America (USA) housing stock is detached, with Perth eclipsing all of the major 25 USA metropolitan areas in terms of detached housing (U.S. Department of Commerce, 2013). Low population density and outward expansion witnessed in Perth has generated high demand for dispersed amenities and services in a non-strategic, “lot-by-lot fashion” (Dhakal, 2014). Suburbanisation of this nature has been identified as unsustainable due to impacts on ecological systems (e.g. habitat fragmentation) and socio-economic issues (e.g. amenity provisioning costs), with accurate urban area identification essential for sustainable future planning and maximum resource efficiency, particularly in Perth owing to its globally high suburbanisation and distributed population (Western Australian Planning Commission, 2013a).</p>
<p>Figure 5 1. Landsat 8 Operational Land Imager (OLI) true colour image mosaic of the Perth Metropolitan Region (9 August 2015 [path 112] and 17 September 2015 [path 113]). The locations of the high spatial resolution aerial image subsets are indicated by coloured overlays (a), with Western Australia identified in (b) and Perth city (c). Therefore, the PMR provides a globally diverse range of urban characteristics (e.g. compact urban central business district, older residential areas and new suburban developments) facilitating broad dataset comparison opportunities between Landsat and high spatial resolution urban area estimates. The high spatial resolution data identifies the complexity of these suburban and urban areas, which is obscured in medium and coarse spatial resolution datasets. This permits the extraction of individual features such as buildings, roads and vegetation that compose the urban environment and which are represented as a spectrally mixed pixel in Landsat imagery (illustrated in Figure 5 2) (Myint et al., 2011).</p>
<p>Figure 5 2. Comparison of true colour high spatial resolution data (a) (acquired from 14 March 2007) and Landsat surface reflectance (b) (acquired on 6 October 2007 [path 112]), highlighting the spatial detail captured by high-resolution imagery (c) and the same areas as observed by Landsat (d) for the subset East Beechboro used within this study. Definitive feature detection from high resolution data can assist in refining urban area estimates produced from moderate spatial resolution satellite imagery (Lu et al., 2011; Wu and Murray, 2003). More accurate satellite derived urban area estimates are imperative for ensuring appropriate data use for policy and environmental variable applications in order to mitigate the consequences of unsustainable urban development. This aligns with the criteria of effective land use planning within the City Resilience Framework (CRF) which is designed to improve city resilience (ARUP and The Rockefeller Foundation, 2015).</p>
</div>
<div id="data" class="section level2">
<h2><span class="header-section-number">5.4</span> Data</h2>
<div id="landsat-data" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Landsat data</h3>
<p>Cloud free Landsat scenes were obtained for 2007 from Landsat 5 Thematic Mapper (TM), coinciding with high resolution orthophotos (described in section 5.4.2). Imagery were acquired within winter months (9 July 2007 for path 113 and 6 October 2007 for path 112) corresponding with peak vegetation green-up which limits issues concerning the spectral separation between senescent vegetation, bare earth and some impervious surfaces (Chen et al., 2014; Feyisa et al., 2016). Landsat imagery was processed to standard terrain correction (Level 1T), geometrically and topographically corrected using Ground Control Points (GCPs) and a Digital Elevation Model (DEM) from the Global Land Survey 2000 dataset (Hansen and Loveland, 2012). Landsat 5 TM surface reflectance values were derived from the Landsat Ecosystem Disturbance Adaptive Processing System (LEDPAS) (Hansen and Loveland, 2012; Masek et al., 2006) which corrects for atmospheric effects using the Second Simulation of a Satellite Signal in the Solar Spectrum (6S) radiative transfer model (Vermote et al., 1997).</p>
</div>
<div id="high-spatial-resolution-airborne-imagery" class="section level3">
<h3><span class="header-section-number">5.4.2</span> High spatial resolution airborne imagery</h3>
<p>Radiometrically calibrated multispectral red (0.58-0.77 µm), green (0.48-0.63 µm), blue (0.41 µm -0.54 µm) and near-infrared (0.69-1.00 µm) orthophotos were acquired over 19 cloud free days commencing on 14 March 2007 as part of the Perth and Peel Urban Monitor Programme (Caccetta et al., 2012). Aerial imagery, obtained between 10:00 and 14:00 to reduce shadow effects, were captured using a Microsoft UltraCAM-D at a height of 1300m resulting in a spatial resolution of 20 cm. Forward and side frame overlap of 60% and 30% respectively permitted automatic Digital Surface Model (DSM) extraction using geometric control points provided by WA’s land information authority (Landgate). Extraction of ground points exclusively representing terrain variations facilitated derivation of a Ground Elevation Model (GEM) which, when subtracted from the DSM, generated a Relative Elevation Model (REM), depicting elevation relative to ground points.<br />
Spatial and temporal inconsistencies in reflectance can arise from atmospheric scattering and absorption; instrument noise and Bidirectional Reflection Distribution Function (BRDF) effects. The latter describes the systematic variation in reflectance across an image due to differences in view and illumination angles and which is dependent on the surface 3D structure (Collings et al., 2011). The orthophotos were provided as a surface reflectance product, corrected for multiplicative and additive errors over frames (e.g. instrument noise and atmospheric effects) and within frame viewing and illumination geometry (Caccetta et al., 2012; Collings et al., 2011). Image preprocessing consisted of two steps. Firstly, a combined BRDF and atmospheric correction procedure was applied to retrieve surface reflectance for each image acquisition. Linear BRDF model parameters from the Li Sparse reciprocal kernel (Wanner et al., 1995) were used to correct for BRDF effects. Atmospheric perturbations were corrected by assuming that the obtained digital number represented the relative reflectance affected by spatially dependent multiplicative and additive terms. These combined steps generated an internally consistent mosaicked dataset. ‘True’ surface reflectance was estimated through fitting global offset and gain values to replicate laboratory measured calibration targets based on the assumption that relative reflectance requires a linear transformation to true reflectance (Collings et al., 2011).</p>
</div>
</div>
<div id="methodology" class="section level2">
<h2><span class="header-section-number">5.5</span> Methodology</h2>
<div id="landsat-preprocessing" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Landsat preprocessing</h3>
<p>The two Landsat scenes covering the study area were combined to form a seamless image mosaic following the methodology of Pan et al. (2009). Voroni diagrams were created on the bisector between images with adjacent edges defined as seamlines, identifying effective mosaic polygons that specify pixels from each image to include in the final mosaic, facilitating less visible boundaries through blending of overlapping pixels (Pan et al., 2009) (Figure 5 1 (a)). Due to remaining residual noise in the mosaicked imagery caused by factors such as the brightening effect of thin clouds and atmospheric correction differences, surface reflectance values were standardised following the approach identified by Sexton et al. (2013):</p>
<p>p_(i,b)=p_(x,b)/〖max〗_b (5.1)</p>
<p>where p_(i,b) is the standardised pixel value i, from band b based on the original surface reflectance x, standardised through division by a waveband specific upper reflectance limit which are: 0.10 (blue; 0.48µm), 0.11 (green; 0.56µm), 0.12 (red; 0.66µm), 0.23 (near-infrared; 0.84µm), 0.21 (shortwave-infrared; 1.65µm), 0.15 (shortwave-infrared 2; 2.22µm). The standardised values (p_(i,b)) were then normalised against the summed band standardised values:</p>
<p>p_(j,b)=p_(i,b)/(∑<em>i▒p</em>(i,b) ) (5.2)</p>
<p>where ∑<em>i▒p</em>(i,b) is the sum of each standardised pixel across all bands (Sexton et al., 2013). This approach has been found to satisfactorily reduce variations generated from inherent residual noise across mosaicked imagery, for example due to differences in modelled atmospheric parameters within the LEDAPS algorithm (Luo et al., 2014; Sexton et al., 2013) (Figure 5 3 (a)). Statistical assessment of image radiometric normalisation provided in MacLachlan et al. (2017a) found that the post-processed Landsat data exhibited significantly lower inter and intra Coefficient of Variation (CV) when compared to the pre-processed data.</p>
<p>Figure 5 3. Summary of classification procedures for (a) Landsat and (b) high-resolution orthophoto data.</p>
</div>
<div id="landsat-classification" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Landsat classification</h3>
<p>The 2007 Landsat data was classified as a time series of data for seven sequential periods between 1990 and 2015 using an IVM classifier produced in MacLachlan et al. (2017a). The method uses a hybrid strategy which assesses whether new samples (termed import vectors) can be removed in each forward step in order to provide a smoother decision boundary which ideally leads to a more accurate solution (Roscher et al., 2012). Samples are selected based on how much their incorporation decreases the objective function to minimise the decision boundary to form the optimal separating hyperplane between overlapping clusters (e.g. land cover types) in spectral feature space (Mountrakis et al., 2011; Roscher et al., 2012; Zhu and Hastie, 2005). IVM generates two outputs, a soft (sub-pixel) dataset which defines the probability of a pixel containing a given classification value (e.g. land cover type) and a traditional ‘hardened’ classified dataset (Braun et al., 2012). Training samples were collected from the 12th and 19th July 2005 Landsat 5 TM image composite, coinciding with peak vegetation greenness which provides the greatest spectral separability between vegetated and non-vegetated surfaces (Chen et al., 2014; Feyisa et al., 2016). Six land cover types were defined based on existing literature (e.g. Feyisa et al., 2016; Hu and Weng, 2009; Schneider, 2012) and scene analysis which are high reflectance urban (e.g. concrete), low reflectance urban (e.g. asphalt), forest, water, grassland and bare earth. Two urban land cover classes are specified to reduce spectral confusion between spectrally similarly classes (e.g. urban and bare earth) (Hu and Weng, 2009). For each land cover type, 250 pixels were randomly identified from across the image for training the IVM classifier which follows the approach used by Foody and Mather (2006) and Pal and Mather (2003). The IVM algorithm is parameterised using the training data that generates a classification model consisting of spectral profiles for each land cover type, which are then matched to the Landsat mosaic during classification.</p>
<p>The resulting per-pixel (hardened) classification indicates that the total urban extent of the PMR has increased 45.32% (sub-pixel estimate of 32.96%) between 1990 (hardened estimate 706.88 km2, sub-pixel estimate 736.93 km2) and 2015 (hardened estimate 1027.22 km2, sub-pixel estimate 979.84 km2) (MacLachlan et al., 2017a). This can be broken down into low reflectance urban cover expanding from a hardened value of 592.83 km2 (sub-pixel estimate 668.46 km2) to 839.00 km2 (sub-pixel estimate 850.87 km2) and high reflectance urban cover increasing from a hardened value of 114.05 km2 (sub-pixel estimate 135.32 km2) to 188.20 km2 (sub-pixel estimate 214.06 km2) across the same temporal period.</p>
</div>
<div id="google-earth-landsat-accuracy-assessment" class="section level3">
<h3><span class="header-section-number">5.5.3</span> Google Earth Landsat accuracy assessment</h3>
<p>Google Earth imagery consistent with the Landsat acquisition date was used to assess the accuracy of the hardened Landsat classification following previously published methods (e.g. Bagan and Yamagata, 2014; Cunningham et al., 2015; Dorais and Cardille, 2011; Song et al., 2016; Sun et al., 2015; Zhu and Woodcock, 2014). Using the Google Earth imagery, 300 random locations (50 per land cover class) within the PMR which were visually identified and compared to the classified land cover data, consistent with recommended land cover accuracy sample size of Congalton (2001) (Song et al., 2016). The 2007 Landsat classification obtained an accuracy of 84.00% and a Kappa Coefficient of 0.78. Urban land cover estimates had a producer’s accuracy of 83.00% and user’s accuracy of 87.37%. MacLachlan et al. (2017a) provide a full breakdown of urban temporal change and associated accuracy for all imagery in the Landsat time series (1990-2015), with the Landsat classification data available from the pangaea open access publisher (DOI: 10.1594/PANGAEA.871017) (MacLachlan et al., 2017b).</p>
</div>
<div id="aerial-image-classification" class="section level3">
<h3><span class="header-section-number">5.5.4</span> Aerial image classification</h3>
<p>Urban areas are complex, heterogeneous environments which are challenging to classify even when using high spatial resolution multi-spectral imagery (Lu et al., 2011; Varshney and Rajesh, 2014). Within urban areas, traditional moderate and coarse spatial resolution pixel based classification methods present multiple challenges due to the land surface spatial heterogeneity and the spectral similarity between urban and non-urban materials (Myint et al., 2011). To characterise the influence of spatial resolution on the ability to map urban areas, high spatial resolution multispectral ortho-imagery (20 cm) were classified into the four broad land cover types. To reduce data processing requirements, four 3 km2 subsets were chosen that are representative of the land cover composition and spatial heterogeneity found within Perth (Figure 5 1 (a)). These subsets are an out of town development area (East Beechboro), the Central Business District (CBD), an older suburban area (Palmrya, Melville) and a largely vegetated region (Keysbrook). Using the high spatial resolution multispectral imagery and a relative elevation model, an Object Based Image Analysis (OBIA) method was applied to classify each subset into vegetation, urban, bare earth and water (Figure 5 3 (b)). OBIA methods are often applied to high spatial resolution imagery as they include spatial, textural and spectral information to classify the scene (Myint et al., 2011). Incorporating surface elevation measurements into urban classifications has been found to improve building (urban) extraction accuracy (Aguilar et al., 2012; Poznanska et al., 2013). Surface elevation estimates and Normalised Difference Vegetation Index (NDVI) data provided additional urban classification parameters, with refinement (e.g. additions and alterations) made based on object spatial, spectral and textural properties. Unlike the Landsat imagery, the airborne imagery were collected during the late dry season when the grass was senescent which resulted in textural and spectral similarity between bare earth and roads. To mitigate the impact of potential misclassification between these features, Landgate road and, where appropriate, rail vector datasets were used for identification of coincident image objects for urban assignment.</p>
<p>Table 5 1. The percentage of different land-cover types within the classified high spatial resolution subsets (Figure 5 1). Subset Vegetation (%) Urban (%) Bare earth (%) Water (%) East Beechboro 81.00 16.56 2.37 0.07 CBD 33.33 65.66 0.91 0.10 Palmrya 57.29 42.21 0.42 0.08 Keysbrook 97.36 0.90 1.56 0.18</p>
</div>
<div id="dataset-comparison-and-landsat-refinement" class="section level3">
<h3><span class="header-section-number">5.5.5</span> Dataset comparison and Landsat refinement</h3>
<p>In order to compare the orthophoto and Landsat land cover classifications, the two urban (high and low reflectance) and two vegetation (woodland and grassland) Landsat land cover classes were merged so that both land cover classifications contained four identical classes. To facilitate comparison between the high spatial resolution orthophoto-derived classification and the Landsat classification, the orthophoto land cover data is aggregated to Landsat spatial resolution to provide a ‘soft’ and a ‘hard’ land cover dataset. To create the soft 30 m2 orthophoto-derived classification, each resampled 30 m2 pixel area contains the proportion of each land cover type within it (Lu et al., 2011) (Figure 5 3 (b)). This dataset was subsequently ‘hardened’ by assigning the pixel land cover type according to the dominant land cover found within the 30 m2 area. The comparison methodology is to firstly compare the per-pixel (i.e. hardened) Landsat land cover classification with the aggregated (30 m2) orthoimage classification. Misclassified Landsat pixels are assessed further to establish the conditions that lead to erroneous classification using the sub-pixel proportion information (i.e. soft classification datasets). The latter are also used to identify a spatially explicit correction model to improve urban area estimates from moderate spatial resolution imagery.</p>
</div>
</div>
<div id="results-1" class="section level2">
<h2><span class="header-section-number">5.6</span> Results</h2>
<div id="orthophoto-and-landsat-land-cover-comparison" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Orthophoto and Landsat land cover comparison</h3>
<p>A comparison is conducted between the orthophoto land cover classification, aggregated to 30 m2 spatial resolution using the majority land cover, and the IVM ‘hardened’ Landsat classification. At its native spatial resolution (20 cm; Figure 5 4 ((a-d)(i))), the orthophoto land cover classification (Figure 5 4 ((a-d)(ii))) captures the land cover spatial heterogeneity found within each region and highlights the difference in the spatial structure between these regions.</p>
<p>Figure 5 4. (i) High spatial resolution true colour orthophotos, (ii) land-cover maps, and (iii) the agreement between the orthophoto classification resampled to 30 m2 and the Landsat classification for: (a) an out of town development area (East Beechboro), (b) old inner city urban area (central business district), (c) older suburban area (Palmrya, Melville), and (d) predominantly vegetated site (Keysbrook). In (iii), areas depicted as ‘true’ indicate those 30 m2 pixels where the orthophoto land-cover type, based on the dominant land cover in the 30 m2 area, and Landsat land-cover type are in agreement. A comparison is carried out between the orthophoto land cover classification, aggregated to 30 m2 spatial resolution, and the ‘hardened’ Landsat classification. Figure 5 4 (iii) illustrates the spatial agreement between these datasets and highlights those pixels where the same land cover type (true) has been assigned to a pixel in both classifications. The areas which are more homogeneous at Landsat’s spatial resolution, such as the CBD (urban, Figure 5 4 (b)) and Keysbrook (vegetation, Figure 5 4 (d)), have greater level of agreement (73.14% and 95.68% respectively). In contrast, the more heterogeneous subsets (East Beechboro and Palmrya, Figure 5 4 (a and c)), have much lower levels of agreement (56.09% and 32.03% respectively). The differences in agreement result from the sub-pixel heterogeneity at 30 m2 spatial resolution. Table 5 2 shows the percentage of Landsat pixels which contain &gt;50% of a given land-cover for each subset region.</p>
<p>Table 5 2. The percentage of pixels which contain &gt;50% of a given land-cover type in each region. Subset Vegetation (%) Urban (%) Bare earth (%) Water (%) East Beechboro 87.57 9.84 1.89 0.06 CBD 26.14 72.81 0.74 0.05 Palmrya 66.71 32.33 0.21 0.07 Keysbrook 98.90 0.05 0.88 0.11</p>
<p>To investigate the influence of sub-pixel heterogeneity on the ability of Landsat to identify the pixel land cover type, the classification accuracy is determined as a function of the percentage of urban area within each Landsat pixel for all four subsets (Figure 5 5). The urban percentage cover within each Landsat pixel is derived from the orthophoto land cover classification which has been aggregated to 30 m2 and which provides the proportion of each land cover within each pixel. The accuracy of the hardened Landsat classification was determined through comparison against the ‘hardened’ (e.g. aggregated to 30 m2) orthophoto land cover classification where the per-pixel land cover type was determined based on the land cover type with the greatest sub-pixel proportion. Figure 5 5 indicates that the hardened Landsat classification results in a relatively high accuracy, with an average of 85.40% (excluding Keysbrook), for pixels containing &gt;50% urban land cover (according to the high spatial resolution land cover classification). In the subsets of East Beechboro, the CBD and Palmrya, the overall Landsat classification accuracy drastically declines to 1.99-6.21% when urban land cover within a 30 m2 pixel area decreases to 40-50%. The classification accuracy then increases with decreasing sub-pixel urban cover which is particularly evident with Landsat pixels containing 0-10% urban cover. Keysbrook, on the other hand, is a largely vegetated region and exhibits lower accuracy with increasing urban land cover.</p>
<p>Figure 5 5. Landsat classification accuracy as a function of the percentage urban cover within Landsat image pixels (as derived from the high spatial resolution land-cover data set) for each of the four subsets. In the Keysbrook subset, no Landsat pixels contained &gt;60% urban land cover.</p>
<p>In order to understand the counter-intuitive behaviour of such as rapid decrease in classification accuracy in pixels which contain between 40-50% urban area (Figure 5 5), an analysis of the percentage of pixels classified as a given land cover type is presented. To do so, all pixels containing different ranges in urban percentage cover (e.g. 0-10%, 20-30% etc) were identified using the high spatial resolution land cover dataset. The total percentage of each land cover type was calculated for all pixels that contained urban percentage cover within each range urban percentage cover (e.g. 0-10%, 20-30% etc) using hardened IVM Landsat land cover dataset and the aggregated high spatial resolution land cover dataset (i.e. defined by the dominant land cover type within a 30 m2 pixel area).</p>
<p>Figure 5 6 illustrates the percentage of pixels identified as a given land cover type as indicated by the hardened Landsat land cover dataset and the hardened high spatial resolution orthophoto land cover dataset for pixels which contain differing percentage urban cover (e.g. 0-10%) derived using the original high spatial resolution orthophoto land cover classification for the East Beechboro subset. This area was selected as it is an intermediate area in terms of land cover heterogeneity (Figure 5 2 and Figure 5 4 (a)). The results indicate that the hardened Landsat classification consistently overestimates urban land cover when compared to the ‘hardened’ high spatial resolution classification which has been aggregated to 30 m2 based on the dominate land cover within the Landsat pixel area for pixels with 10-50% urban defined by high resolution data. Table 5 3 and Figure 5 7 illustrates the sub-pixel (30 m2) percentage urban land cover for East Beechboro with the original reflectance imagery for this area shown in Figure 5 2. The hardened high spatial resolution land cover dataset (left bar in each plot (Figure 5 6)) indicates that pixels containing &lt;50% urban land cover are largely dominated by vegetation. In contrast, Landsat largely identifies these pixels as being either urban or vegetated to differing extents and more correctly identifies pixels with 0-10% urban land cover as being predominantly vegetated. For example, pixels containing 40-50% urban area are correctly identified as being vegetated (98.45% of pixels within this range) by the hardened high spatial resolution land cover dataset since these pixels contain on average 54.72% vegetation, 44.83% urban and 0.45% bare earth. In contrast, the hardened Landsat land cover dataset identifies 5.65% of pixels containing 40-50% urban cover as being vegetation, 74.28% being urban and 20.07% being bare earth. As the percentage of urban land cover decreases, the overall accuracy of the hardened Landsat classification increases due to the increase in Landsat vegetation cover which increases from 5.65% (40-50% urban cover) to 75.41% (0-10% urban cover). The results are similar for the other regional subsets. The rapid decrease in accuracy between 40-50% and 50-60% (Figure 5 5) appears extreme as the subset regions are dominated by vegetation and urban land cover (Table 5 1) which results in the aggregated 30 m2 pixels being assigned to vegetation when the percentage urban cover is &lt;50% (Figure 5 6 (a-e)) or urban when the percentage urban cover is &gt;50% (Figure 5 6 (f-j)).</p>
<p>Figure 5 6. Land-cover type disaggregation for urban land cover (according to the orthophoto imagery) Landsat pixels in East Beechboro. The left axis indicates the total percentage cover of a given land-cover type using all of the pixels within a given range of urban percentage cover range for: (a) 0–10%, (b) 10–20%, (c) 20–30%, (d) 30–40%, (e) 40–50%, (f) 50–60%, (g) 60–70%, (h) 70–80%, (i) 80–90%, and (j) 90–100%. For each percentage urban land-cover graph, the left bar illustrates the overall percentage of pixels from the hardened high spatial resolution classification identified as a given land types whilst the right bar indicates the percentage of hardened Landsat pixels mapped as a given land-cover type. Table 5 3. Urban area estimates (km2) from high spatial resolution orthophoto land cover data for each subset and those from the corresponding hard and soft IVM Landsat classification. The overestimation of urban area by the hardened Landsat land cover classification is evident. Percent difference to high resolution (%) 111.69 21.62 81.42 266.26 Percentage cover of subset area (%) 35.06 79.85 76.55 3.30 Landsat urban area sub-pixel (km2) 3.12 6.78 4.90 0.39 Percent difference to high resolution (%) 118.66 30.54 103.60 252.22 Percentage cover of subset area (%) 36.21 85.71 85.94 3.17 Landsat urban area (km2) 3.22 7.28 5.50 0.28 Percentage cover of subset area (%) 16.56 65.66 42.21 0.90 High resolution urban area (km2) 1.47 5.58 2.70 0.08 Subset East Beechboro CBD Palmrya Keysbrook</p>
<p>Figure 5 7. Comparison of percentage urban area aggregated to 30 m2 from high-resolution data (a) and IVM ‘soft’ Landsat classification (b) highlighting the (overestimation) between the high (c) and moderate (d) spatial resolution estimates for the East Beechboro subset. The classified high spatial resolution data are shown in (e) with the moderate spatial resolution grid (30 m2) overlaid for context (e).</p>
<p>The results in Figure 5 6 suggest that the spectral data used to train the IVM classification (discussed in section 5.5.2) contained spectrally ‘mixed’ pixels resulting in land cover type misclassification. To investigate this, the spectral reflectance from Landsat pixels containing 20-30% urban cover for the Palmrya subset, which had the lowest overall agreement and which were identified as being mostly vegetated by the hardened high spatial resolution land cover dataset, are extracted and compared to the spectral reflectance profiles used to train the IVM classification algorithm. Figure 5 8 indicates that there are strong similarities between the average spectral reflectance profile used to train the IVM classification algorithm and the average spectral profile of the misclassified pixels. This suggests that the IVM classification algorithm is accurately representing the Landsat pixel spectral reflectance properties but that the training data used to develop the classification model contained a high proportion of mixed pixels.</p>
<p>Figure 5 8. Average spectral reflectance profile for misclassified pixels (red) from the Palmrya subset for pixels containing 20–30% urban cover compared to the average spectral reflectance profile of pixels used to train the IVM classification algorithm (blue). For (a) forest, (b) low urban reflectance, (c) high urban reflectance, and (d) bare earth. The error bars show the standard deviation.</p>
<p>Pure (i.e. homogeneous) pixels are conventionally selected to train classification models (e.g. Weng and Pu, 2013) but these are inherently difficult to identify in urban areas owing to the multitude of land covers within a Landsat pixel area. Using the high spatial resolution classification, the percentage of pure pixels, defined here as those containing between 90-100% of a single land cover type, were identified (Table 5 4). It is evident that some regions contain a high percentage of pure pixels for a given land cover type, such as vegetation in Keysbrook (92.05%), but that other land cover types within a region typically have much lower percentages of pure pixels. Pure urban pixels are particularly limited in all subset regions. Whilst the CBD subset obtains a high percentage of pure urban pixels (28.77%) these are predominately urban areas with high spectral reflectance (e.g. concrete), differing from subsets with urban areas which have urban areas with both high and low spectral reflectance (e.g. East Beechboro; Figure 5 2).</p>
<p>Table 5 4. Percentage of ‘pure’ pixels (defined here as comprising 90-100% of given landcover within a Landsat pixel area) from the high spatial resolution imagery. Subset Vegetation (%) Urban (%) Bare earth (%) Water (%) East Beechboro 53.93 0.15 0.34 0.03 CBD 8.98 28.77 0.35 0.00 Palmrya 5.80 2.13 0.00 0.01 Keysbrook 92.05 0.00 0.00 0.00</p>
</div>
<div id="comparison-between-landsat-and-high-spatial-resolution-impervious-surface-estimates" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Comparison between Landsat and high spatial resolution impervious surface estimates</h3>
<p>Landsat data have been widely applied to map impervious surface area in order to assess its effects on: urban growth dynamics (Masek et al., 2000), the UHI effect (Hu et al., 2015) and surface run-off (Weng, 2001). Figure 5 6 indicates that the ‘hardened’ Landsat IVM classification overestimates urban land cover, particularly for pixels containing &lt;50% urban area. The IVM classifier also provides a ‘soft’ land cover dataset that quantifies the sub-pixel land cover proportions.</p>
<p>Here we investigate the utility of the sub-pixel Landsat urban land cover estimates by comparing them to those derived from the high spatial resolution land cover dataset (20 cm) which is used to provide the actual land cover proportion within each 30 m2 pixel area. Urban area estimates from each of the four subsets (Figure 5 1 (a)) were spatially averaged over different size spatial windows (30 × 30 m, 90 × 90 m, 150 × 150 m and 210 × 210 m) in order to account for any errors resulting from pixel heterogeneity, spatial misregistration, residual atmospheric and BRDF effects and phenological differences (Ghimire et al., 2010; Ju et al., 2012; Liang et al., 2001; Lu et al., 2011; Maiersperger et al., 2013) that may increase the uncertainty in estimating land cover proportions (Lu et al., 2011; Sexton et al., 2013). Comparison of impervious surface proportions at 30 m2, for example the CBD subset (Figure 5 9), reiterates the overestimation of urban area at 30 m2 spatial resolution, with a clustering of values toward the upper percentage boundaries associated with lower urban area estimates from the high spatial resolution classification. When neighbourhood averaging is applied, the agreement in urban area typically improves with increasing window size although the subset specific bias remains consistent (Table 5 5). It is also evident that urban area is still overestimated with decreasing urban sub-pixel proportion even when utilising the sub-pixel IVM Landsat classification results.</p>
<p>Figure 5 9. Relationship between the sub-pixel urban area percentage cover estimated from the IVM sub-pixel Landsat classification and the high spatial resolution orthophoto classification in the Central Business District (CBD) subset for (a) 30 × 30 m window, (b) 90 × 90 m window, (c) 150 × 150 m window, and (d) 210 × 210 m window.</p>
<p>Table 5 5. Comparison between high (20 cm2) and moderate (30 m2) spatial resolution sub-pixel impervious surface estimates considering differing kernel sizes over four subsets (Figure 5 1) within the PMR.</p>
<p>Subset Kernel size (m) R2 Scatter Bias Root Mean Square Error (RMSE) East Beechboro 3030 0.41* 26.65 18.68 32.54</p>
<pre><code>9090   0.68*   16.95   18.66   25.21
150150 0.75*   14.11   18.71   23.44
210210 0.80*   12.52   18.74   22.54</code></pre>
<p>CBD 3030 0.26* 28.41 14.38 31.84 9090 0.53* 16.65 14.37 22.00 150150 0.61* 13.18 14.38 19.51 210210 0.66* 11.30 14.36 18.28 Palmrya 3030 0.04* 26.65 34.54 43.62 9090 0.16* 13.56 34.61 37.17 150150 0.19* 10.15 34.64 36.10 210210 0.17* 8.45 34.67 35.69 Keysbrook 3030 0.24* 11.85 2.51 12.11 9090 0.52* 7.47 2.51 7.88 150150 0.60* 5.89 2.50 6.40 210210 0.63* 4.98 2.50 5.57</p>
</div>
<div id="refining-landsat-estimations-using-high-spatial-resolution-data" class="section level3">
<h3><span class="header-section-number">5.6.3</span> Refining Landsat estimations using high spatial resolution data</h3>
<p>Sub-pixel land cover heterogeneity influences Landsat urban area overestimation which must be considered in order to reduce the bias and improve Landsat derived urban area estimation (Herold et al., 2002; Lu et al., 2011; Schneider, 2012; Varshney and Rajesh, 2014). The complexity and diversity of urban areas identified here from high spatial resolution data, with biases ranging from -2.50% to -34.67%, highlights the inappropriateness of applying a single model to adjust the moderate spatial resolution urban area estimates in a metropolitan region (e.g. Lu et al., 2011). The Landsat sub-pixel urban areas estimates from all four subsets were stratified based on the Landsat sub-pixel derived urban area and calibrated against the percentage of urban area from the high spatial resolution classification within each moderate spatial resolution pixel area. Both datasets were averaged at the neighbourhood level using a 210 × 210m window as this provided the best overall relationship (Table 5 5). Stratification of Landsat sub-pixel urban estimates into divisions of 10%, consistent with previous results, were selected to develop (using 50% of the data) and test (remaining 50% of the data) regression models to improve the dataset agreement (Lu et al., 2011). The applied spatially explicit models reduced the bias and Root Mean Square Error (RMSE) between the predicted (moderate spatial resolution) and observed (high spatial resolution) estimates (Table 5 6). It is evident from Table 5 6 that the adjustment made to the Landsat urban area estimates reduced the overestimation difference of urban area by between 34.38% and 80.67%, with the largest improvement found within Keysbrook. Whilst the corrected Landsat urban area estimates still overestimates the urban area compared to the high spatial resolution dataset the corrected moderate spatial resolution urban area reduces moderate resolution urban area over (under) estimation by on average 55.08% in comparison to the high spatial resolution dataset reducing the average overestimation from 11.86 km2 per subset to just 0.09 km2 (Table 5 6). In the case of this study area, this approach is appropriate for producing more accurate urban area statistics. Due to the frequently reported over and under estimation of land cover estimates by moderate spatial resolution data this approach can refine urban estimates for planning development policies that may inform decision makers (Hepinstall-Cymerman et al., 2013; Schneider et al., 2005; Zhu and Woodcock, 2014). However, the derived correction values are not globally applicable since the spatial structure and makeup of urban and suburban areas varies regionally, nationally and globally. Nevertheless the methodology implemented here could be replicated to produce localised correction values from other sources of high resolution imagery (e.g. digitisation of Google Earth imagery) to calibrate urban area estimates from moderate spatial resolution data.</p>
<p>Table 5 6. Comparison between calibrated moderate (30 m2) and high (20 cm2) resolution sub-pixel impervious surface estimates with a kernel size of 210m. * = statistically significant relationship (p&lt;0.05). Corrected percent difference to high resolution (%) 8.83 -11.93 15.71 35.29 Corrected Landsat urban (km2) 2.72 10.88 8.10 0.19 Uncorrected percent difference to high resolution (%) 72.47 22.45 57.32 115.96 Uncorrected Landsat urban (km2) 5.32 15.36 12.48 0.50 High resolution urban (km2) 2.49 12.26 6.92 0.13 Root Mean Square Error (RMSE) 6.76 14.61 12.53 1.38 Bias 1.54 -7.12 7.43 0.37 R2 0.84* 0.52* 0.12* 0.62* Subset East Beechboro CBD Palmrya Keysbrook</p>
</div>
</div>
<div id="discussion-1" class="section level2">
<h2><span class="header-section-number">5.7</span> Discussion</h2>
<p>Refined urban estimates are vital in ensuring suitable sustainable and strategic planning decisions are implemented (Bettencourt and West, 2010; Wu and Murray, 2003). The hybrid spatial resolution approach applied here to estimate urban area was necessary due to the difficulty in accurately estimating urban area using a traditional per-pixel classification methods. This was due to a combination of the sensors moderate (30 m2) spatial resolution, land surface heterogeneity and the selection of ‘mixed’ pixels for use in training the classification algorithm. The overall classification accuracy, determined using Google Earth imagery, was on average 84.00%, which is similar to that found in other studies, albeit for different urban areas (e.g. Bagan and Yamagata, 2014; Gislason et al., 2006; Luo et al., 2014; Sundarakumar et al., 2012). Closer examination of the moderate spatial resolution classification results using a higher resolution dataset indicates that when urban land cover within a 30 m2 area decreases to 40-50% (based on high spatial resolution classification) the Landsat classification accuracy decreased from 85.40% to between 1.99 and 6.21%. This resulted from the Landsat classification overestimating urban area in comparison to high spatial resolution data (Figure 5 5) which more correctly identified these pixels as containing a greater per-pixel proportion of vegetation. Pixels containing 40-50% urban cover, contained on average 54.50% vegetation cover excluding Keysbrook. The dominance of vegetation and urban land covers in the regional subset, when ascribed to a 30 m2 pixel area based on the majority land cover, results in a rapid change in classification accuracy. Strong spectral similarities between training data and misclassified pixels (Figure 5 8) suggests that the spectral reflectance observations used to train the classification algorithm contained spectrally mixed pixels. The average percentage urban area within a moderate spatial resolution pixel area derived from the high resolution data was 16.56%, 65.66%, 42.21% and 0.90% for East Beechboro, CBD, Palmyra and Keysbrook respectively. The percentage of ‘pure’ pixels, defined as those containing over 90% urban land cover, was 28.77% for the CBD but &lt;2.50% for the suburban regional subsets. This highlights the difficulty in selecting pure pixels at moderate spatial resolution and in accurately disentangling mixed spectral reflectance’s without the aid of high spatial resolution data. Overestimation of urban extent was most prominent in Keysbrook, where vegetation dominates the subset (97.36%, Table 5 1). In this instance, Landsat derived urban area corresponded to 0.28 km2 compared to 0.08 km2 from high spatial resolution classification; a difference of only 0.20 km2 but which equates to 251.74%. In terms of total area difference, the East Beechboro and the CBD Landsat subsets were found to contain 1.75 km2 and 1.70 km2 more urbanised area, whilst Palmyra data overestimated urban area by 2.79 km2 compared to the high spatial resolution equivalent due to its suburban nature and associated pixel heterogeneity (Figure 5 4).</p>
<p>Spatially averaging the Landsat and orthophoto land cover classifications, to account for potential errors in the datasets (Ghimire et al., 2010), improved their relationship although Landsat still overestimated urban area with differing bias per subset. Over (under) estimation of urban land from Landsat estimations could result in an under (over) prediction on further environmental variables (e.g. UHI) or policy applications. Multiple studies have used classified per-pixel moderate spatial resolution data to influence policy changes through monitoring urban growth (e.g. Hepinstall-Cymerman et al., 2013; Schneider et al., 2005). However, per-pixel methodologies fail to address the issue of mixed pixels, which, as shown here, can result in overestimation of urban area (average: 126.25%, equivalent to 57.58 km2 within the PMR) (Lu et al., 2011). Sub-pixel methods attempt to remedy this issue, but have been found to inaccurately separate impervious land cover from other land cover types resulting in poor representation of impervious surface area (Lu et al., 2011). Consequently over estimation of urban area may have resulted in sub-optimal policies that fail to maximise resource and amenity efficiency (Downs, 2005; Turner et al., 2010).</p>
<p>Calibrating Landsat urban estimates using high spatial resolution data reduces the bias, RMSE and improves urban area estimation. However, the range of bias values across subsets of differing urban land cover characteristic highlights the inappropriateness of a single regression model due to pixel heterogeneity influencing overestimation (Lu et al., 2011). Spatially explicit models, as presented here, permit varying moderate spatial resolution refinement by considering the influence of surface heterogeneity. Whilst the limited availability of low cost high spatial resolution data can preclude analysis of this type, subset digitisation of Google Earth or Unmanned Aerial Vehicle (UAV) imagery may provide a suitable alternative for calibrating Landsat data for improved urban area estimates. Enhanced estimates of urban area would facilitate planning policies which avoid potential environmental and socio-economic consequences of urban development than can result from policies based on over (or under) predicted urban area (ARUP and The Rockefeller Foundation, 2015). For example, classified Landsat data was used to identify spatial clustering, peri urban development and specialisation of land use in Chengdu, Sichuan province not considered by China’s original 1990 Go West policy, aimed at economically boosting the West of the country. Results were used to reform policy and remediate issues of urban management including: service, infrastructure and resource deficiencies (Schneider et al., 2005). However, traditional Landsat classification may over (or under) estimate urban area and result in ineffective planning, environmental and policy decisions (Miller and Small, 2003; Pravitasari et al., 2015). Therefore classified sub-pixel data alongside high spatial resolution imagery (e.g. UAV, Google Earth, high spatial resolution aerial or satellite imagery) as presented here can refine urban estimates facilitating improved decision making whilst maximising often limited financial resources. This is especially important in developing countries in regards to directing urban development and resources based on factors including: poverty, environmental hazards (e.g. flooding) and current amenity centres (Marfai et al., 2014; Suryahadi and Sumarto, 2003).</p>
</div>
<div id="conclusion" class="section level2">
<h2><span class="header-section-number">5.8</span> Conclusion</h2>
<p>Landsat imagery from 2007 was used to map the urban extent within the PMR using an IVM classifier which provides both a per-pixel and a sub-pixel classified datasets. The 2007 Landsat classification overall average accuracy was 84.00% with associated Kappa coefficient of 0.78. Comparison between the Landsat per-pixel urban area and urban area estimates obtained from a high spatial resolution (20 cm) orthophoto-derived classification indicates that the moderate spatial resolution classification overestimates urban extent by 126.25 % on average, which is equivalent to 57.58 km2 in the study area. Similarly, when the high spatial resolution urban area estimates are compared to those derived using a sub-pixel Landsat classification, the latter still overestimates urban extent by 120.25%.</p>
<p>Accurately quantifying urban expansion within the PMR due to the large population growth over the last decade is important in order to make the efficient use of current resources and to avoid additional amenity, environmental and health expenditure that can impact sprawling cities. Landsat data provides the longest time series of medium spatial resolution imagery to map and monitor urban area. However, the reported over and underestimation inhibits accurate quantification of urbanised land cover which increases uncertainty within global climate models, environmental studies and targeted urban planning policy. Neighbourhood averaging, to account for potential errors in the datasets, improved the agreement between the two datasets but Landsat sub-pixel overestimation still remained. The broad differences in bias between the difference subsets indicates that a single regression model is inappropriate to heterogeneous urban land cover estimates. Therefore, the moderate spatial resolution urban area estimates were corrected using spatially explicit regression models which, on average, across the four subsets reduced the bias and RMSE by 17.02 km2 and 6.65 km2 respectively, whilst reducing moderate resolution urban area over (under) estimation by 55.08% Current and future EO satellites that provide complimentary data with enhanced spatial, spectral and temporal resolution, such as Sentinel-2, may further reduce over or under estimation of urban area experienced by moderate spatial resolution sensors such as Landsat. Similarly, high spatial resolution satellite sensors, such as Worldview-3, are able to remediate discrepancies by capturing the fine spatial detail of urban environments but their cost and small swath limit their widespread application. This might change with companies, such as Planet, which are launching large numbers of small micro-satellites that provide high spatial resolution data more frequently. Accurate urban land cover and land use mapping is essential in understanding the impact of urban expansion on, for example, social-ecological systems and human-health and will improve future sustainable planning of our cities.</p>
</div>
<div id="supplementary-material-1" class="section level2">
<h2><span class="header-section-number">5.9</span> Supplementary material</h2>
<p>This supplementary material sections supports the main chapter and thesis through providing a review surrounding classifier selection, pertinent to the selection of the Import Vector Machine (IVM) classifier implemented in generating the classified Landsat image used within the chapter. A short discussion surrounding other considered approaches and a list of data used within the chapter are also provided to demonstrate the entirety of analytical process.</p>
<div id="classification-methodologies" class="section level3">
<h3><span class="header-section-number">5.9.1</span> Classification methodologies</h3>
<p>Currently two main image analysis techniques exist for urban mapping: spectral indices and classification algorithms. Spectral indices such as the Normalised Difference Built-up Index (NDBI) have been used to delineate urban areas from non-urban (Zha et al., 2003). NDBI identifies built up regions using a ratio of the shortwave-infrared (SWIR) and near infrared (NIR) wavebands and assumes that built up areas have higher SWIR reflectance (Xu, 2008). In comparison to ground truth observations, NDBI-derived classification from Landsat Thematic Mapper (TM) over Nanjing, China was found to result in an overall accuracy of 92.6% (Zha et al., 2003). However, due to the heterogeneous nature of urban environments, the identification of built up areas by thresholding a spectral index is not always reliable (Xu, 2008).</p>
<p>The Impervious Build-up Index (IBI) attempts to mitigate for this by using a combination of a number of thematic indices namely: NDBI, the Soil Adjusted Vegetation Index (SAVI) and the Modified Normalised Difference Water Index (MNDWI) (Xu, 2008). The index amplifies the identification of built up land through the inclusion of ancillary information on the presence of bare surfaces (SAVI) and water bodies (MNDWI) resulting in positive values for pixels identified as being urban (Xu, 2008). Nevertheless, urban areas often remain an inseperable mix of impervious and bare earth surfaces which require additional post-processing to delineate (Stathakis et al., 2012; Sun et al., 2015; Zha et al., 2003).</p>
<p>In the second instance, classification algorithms are defined as parametric (e.g. Maximum Likelihood (ML)) or nonparametric (e.g. Decision Trees (DT)), depending on whether training samples can be represented by a Gaussian probability density function (Donnay and Unwin, 2001; Jensen, 2005). Maximum Likelihood accounts for the variance-covariance within class distributions and has been implemented for monitoring land cover change and to derive sub-pixel proportions (Atkinson et al., 1997; Shalaby and Tateishi, 2007). However, due to the parametric assumption of multivariate normal data, the ML classifier can often fail to represent land cover that might be multimodal (Melgani and Bruzzone, 2004; Mountrakis et al., 2011; Otukei and Blaschke, 2010). An example of this issue is illustrated in semi-arid locations, such as grasslands, which are sensitive to precipitation timing and volume that can result in differing multimodal spectral-temporal profiles (Friedl et al., 2002). A decision tree methodology was utilised to generate the United States of America National Land Cover Database 2001 (NLCD 2001) resulting in a nonparametric approach able to handle continuous and nominal data, interpretable classification rules and swift application (Homer et al., 2004). Nevertheless, DTs can be negatively affected by pruning methods, for example Pessimistic Error Pruning (PEP) introduces a continuity correction value, within error estimation on no theoretical basis, resulting in under or over pruning (Esposito et al., 1997; Otukei and Blaschke, 2010; Pal and Mather, 2003).</p>
<p>More recently, Machine Learning Algorithms (MLA) or ‘expert systems’ (e.g. Support Vector Machine (SVM)) have been implemented for image classification (Jensen, 2005; Okujeni et al., 2014) using an automated inductive approach for identification of patterns in data (Cracknell and Reading, 2014). SVM is a nonparametric binary statistical learning methodology that separates a dataset into example classes (training data) based on a decision boundary, or hyperplane, with an aim to minimise misclassification. The optimal maximum margin separating hyperplane divides the data into a predefined number of classes, with points on the margins termed ‘support vectors’ (Foody and Mathur, 2006, 2004). The underlying benefit of SVM pertains to structural risk minimisation, whereby SVMs are able to minimise error on unseen data without prior assumptions on the distribution (Mountrakis et al., 2011; Vapnik and Chervonenkis, 1971). SVMs are linear binary classifiers which, when deriving more than two classes, require implementation of an additional process, either a one-against-all or one-against-one analysis. One-against-all solves for the multiple optimisation problem, which separates one class from the remaining classes. Comparatively one-against-one combines multiple classifiers and performs pair-wise comparisons using a ‘voting’ process to assign a pixel to a land cover class, based on the class assigned the most votes (Chih-Wei et al., 2008; Mountrakis et al., 2011; Pal and Mather, 2005). Within SVMs implementation of soft margin and kernel methods aid separability through the introduction of additional variables that ignore hyperplane outliers and transform data into high dimensional feature spaces (Euclidean or Hilbert) utilising non-linear functions to identify linear solutions respectively (Braun et al., 2012; Cortes and Vapnik, 1995; Melgani and Bruzzone, 2004; Mountrakis et al., 2011).</p>
<p>SVMs have been extensively used for classification purposes, due to their ability to ignore inherent image errors and to avoid overfitting (Foody and Mathur, 2006; Mountrakis et al., 2011). SVMs have obtained broad applicability for land cover classification using data from a multitude of sensors such as HyMAP (Camps-Valls et al., 2004), Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) (Zhu and Blumberg, 2002) and Landsat (Knorn et al., 2009) producing classification results with accuracies between 85% and 95%.</p>
</div>
<div id="other-considered-data-and-approaches-1" class="section level3">
<h3><span class="header-section-number">5.9.2</span> Other considered data and approaches</h3>
<p>In proposing the research within this chapter multiple other datasets were considered in replace of Landsat. These included: GlobeLand30 (classified Landsat data for 2000 and 2010) (Chen et al., 2015), the European Space Agency’s (ESA) Climate Change Initiative (CCI) annual global land cover (300 m) time series (1992-2015) (European Space Agency, 2017) and yearly MODIS land cover products (500 m or 0.05°) (Friedl et al., 2002). Nevertheless these products are constrained by: resolution, temporal frequency, collection dates to closely match the high resolution imagery and global accuracy assessments that might fail to represent the Perth Metropolitan Region. Additionally, using data produced within chapter 4 enabled greater flow throughout the thesis. Similarly, other datasets under consideration in replace of the high resolution orthophotos included that from Google Earth (through digitisation) and digital elevation data from Geoscience Australia (5 metre resolution) (Geoscience Australia, 2015). However, the potential for analyst error alongside lower resolution elevation data could have potentially exacerbated errors within the classification process. Consequently, object based image analysis of the high resolution orthophotos was selected as it provided a repeatable approach with minimal subjectivity (Myint et al., 2011).</p>
</div>
<div id="chapter-data-list-1" class="section level3">
<h3><span class="header-section-number">5.9.3</span> Chapter data list</h3>
<p>This section provides an overview of the data presented and analysed within this chapter.</p>
<p>Supplementary Table 5 7. Summary of the data, sources and applications used within chapter 5. Data Source Application Classified Landsat land cover data (including sub pixel estimates) from 2007 Raw data information (2 images) Landsat 5 TM, 6/10 (path 112), 9/07 (path 113), row 82 Chapter 4 or (MacLachlan et al., 2017b) Comparison to high resolution urban estimates High resolution (20cm) orthophotos comprised of four spectral bands, digital surface and elevation models Sensor Microsoft UltraCAM-D Collection dates 19 could free days from 14/03/2007 Australian Commonwealth Scientific and Industrial Research Organisation Perth and Peel Urban Monitoring Programme To compare classified high resolution data to that of Landsat in order to remediate Landsat’s overestimation Railway and road vector data Landgate Classification of the high resolution imagery</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="urban-growth-dynamics-in-perth-western-australia-using-applied-remote-sensing-for-sustainable-future-planning.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-Sub-pixel-land-cover.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

</body>

</html>
